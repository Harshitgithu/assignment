{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af471b5c-9366-4feb-9c30-6eaebb245952",
   "metadata": {},
   "source": [
    "## Question-1 :Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fd3774-345b-4a3f-a6e5-f598d1fe27a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Analysis of Variance (ANOVA) is a statistical technique used to compare means among three or more groups. However, for ANOVA to provide valid and reliable results, certain assumptions must be met. Here are the key assumptions of ANOVA and examples of violations that could impact the validity of the results:\n",
    "\n",
    "Independence:\n",
    "\n",
    "Assumption: Observations within each group must be independent of each other.\n",
    "Violation Example: If observations within groups are correlated, it can lead to inflated Type I error rates. For instance, if measurements on individuals within a group are related, ANOVA assumptions may be violated.\n",
    "Normality:\n",
    "\n",
    "Assumption: The residuals (the differences between observed and predicted values) should be normally distributed.\n",
    "Violation Example: If the residuals are not normally distributed, it may affect the accuracy of confidence intervals and hypothesis tests. This is especially important for smaller sample sizes. Transformations or non-parametric alternatives might be considered if normality assumptions are severely violated.\n",
    "Homogeneity of Variances (Homoscedasticity):\n",
    "\n",
    "Assumption: The variances of the residuals should be approximately equal across all groups.\n",
    "Violation Example: If the variances are not equal, the power of the test may be compromised, and the Type I error rate may be affected. This is known as heteroscedasticity. Welch's ANOVA or transformation of the data may be considered in the presence of heteroscedasticity.\n",
    "Interval or Ratio Data:\n",
    "\n",
    "Assumption: The dependent variable should be measured on an interval or ratio scale.\n",
    "Violation Example: If the dependent variable is measured on a nominal or ordinal scale, ANOVA may not be appropriate. In such cases, non-parametric alternatives like the Kruskal-Wallis test may be more suitable.\n",
    "Random Sampling:\n",
    "\n",
    "Assumption: Observations should be randomly and independently assigned to different groups.\n",
    "Violation Example: If the sampling process is not random, and groups are systematically different, it may introduce bias into the results. Randomization helps control for unknown and uncontrollable factors that could affect the validity of the conclusions.\n",
    "It's important to note that ANOVA is robust to violations of assumptions to some extent, especially for larger sample sizes. However, if assumptions are severely violated, alternative methods or transformations may be considered, or caution should be exercised in the interpretation of results. Additionally, exploratory data analysis and diagnostic checks can help identify potential violations and guide decisions about the appropriateness of ANOVA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5db0bf-f663-4f27-89fd-fcf3b419b8b8",
   "metadata": {},
   "source": [
    "## Question-2 :What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0532da-e0c5-461d-aadd-0c47e50921a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Analysis of Variance (ANOVA) is a statistical technique that compares means among different groups. There are three main types of ANOVA, each designed for specific situations:\n",
    "\n",
    "One-Way ANOVA:\n",
    "\n",
    "Situation: Used when there is one independent variable with three or more levels (groups) and the goal is to compare the means of these groups.\n",
    "Example: Suppose you want to compare the average test scores of students across three different teaching methods (A, B, and C). One-way ANOVA can be used to determine if there are significant differences in the mean scores of the three groups.\n",
    "Two-Way ANOVA:\n",
    "\n",
    "Situation: Used when there are two independent variables, and you want to examine the main effects of each variable as well as the interaction effect between them.\n",
    "Example: Consider a study where the performance of students is measured based on two factors - teaching method (A, B) and time of day (morning, afternoon). Two-way ANOVA can help determine if there are significant differences in performance due to the teaching method, time of day, and whether there is an interaction effect between the two.\n",
    "Repeated Measures ANOVA:\n",
    "\n",
    "Situation: Used when the same subjects are used for each treatment, and measurements are taken at multiple time points or under different conditions.\n",
    "Example: Suppose you are conducting a study to assess the impact of a new drug on patients' blood pressure levels, and you measure blood pressure before treatment, after one week, and after two weeks for the same group of patients. Repeated Measures ANOVA can be employed to examine whether there are significant changes in blood pressure over time.\n",
    "These three types of ANOVA allow researchers to analyze data from different experimental designs, depending on the nature of the study and the variables involved. It's essential to choose the appropriate ANOVA based on the specific research question and the design of the experiment. Additionally, if the assumptions of ANOVA are violated, alternative methods or transformations may be considered.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb0886a-df69-4aff-a230-876322aec9b3",
   "metadata": {},
   "source": [
    "## Question-3 :What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a0d40e-2f6f-4c42-9f42-b13c8070e591",
   "metadata": {},
   "outputs": [],
   "source": [
    "In Analysis of Variance (ANOVA), the partitioning of variance refers to the decomposition of the total variance observed in the data into different components. Understanding this partitioning is crucial for interpreting the sources of variability in the data and assessing the significance of the factors being studied. The total variance is broken down into three main components in a one-way ANOVA:\n",
    "\n",
    "Total Sum of Squares (SST):\n",
    "\n",
    "Definition: This represents the total variability in the dependent variable.\n",
    "Formula: \n",
    "�\n",
    "�\n",
    "�\n",
    "=\n",
    "∑\n",
    "�\n",
    "=\n",
    "1\n",
    "�\n",
    "(\n",
    "�\n",
    "�\n",
    "−\n",
    "�\n",
    "ˉ\n",
    ")\n",
    "2\n",
    "SST=∑ \n",
    "i=1\n",
    "n\n",
    "​\n",
    " (X \n",
    "i\n",
    "​\n",
    " − \n",
    "X\n",
    "ˉ\n",
    " ) \n",
    "2\n",
    " \n",
    "Interpretation: SST measures the total variability in the data, regardless of the grouping variable.\n",
    "Between-Group Sum of Squares (SSB):\n",
    "\n",
    "Definition: This represents the variability in the dependent variable that is explained by differences between the group means.\n",
    "Formula: \n",
    "�\n",
    "�\n",
    "�\n",
    "=\n",
    "∑\n",
    "�\n",
    "=\n",
    "1\n",
    "�\n",
    "�\n",
    "�\n",
    "(\n",
    "�\n",
    "ˉ\n",
    "�\n",
    "−\n",
    "�\n",
    "ˉ\n",
    "ˉ\n",
    ")\n",
    "2\n",
    "SSB=∑ \n",
    "j=1\n",
    "k\n",
    "​\n",
    " n \n",
    "j\n",
    "​\n",
    " ( \n",
    "X\n",
    "ˉ\n",
    "  \n",
    "j\n",
    "​\n",
    " − \n",
    "X\n",
    "ˉ\n",
    " \n",
    "ˉ\n",
    " ) \n",
    "2\n",
    " \n",
    "Interpretation: SSB quantifies how much of the total variability can be attributed to the differences between the group means.\n",
    "Within-Group Sum of Squares (SSW):\n",
    "\n",
    "Definition: This represents the variability in the dependent variable that is not explained by differences between the group means and is often referred to as the \"error\" or \"residual\" sum of squares.\n",
    "Formula: \n",
    "�\n",
    "�\n",
    "�\n",
    "=\n",
    "∑\n",
    "�\n",
    "=\n",
    "1\n",
    "�\n",
    "(\n",
    "�\n",
    "�\n",
    "�\n",
    "−\n",
    "�\n",
    "ˉ\n",
    "�\n",
    ")\n",
    "2\n",
    "SSW=∑ \n",
    "i=1\n",
    "n\n",
    "​\n",
    " (X \n",
    "ij\n",
    "​\n",
    " − \n",
    "X\n",
    "ˉ\n",
    "  \n",
    "j\n",
    "​\n",
    " ) \n",
    "2\n",
    " \n",
    "Interpretation: SSW captures the variability within each group that cannot be explained by differences in group means.\n",
    "The relationship between these components is expressed by the identity:\n",
    "�\n",
    "�\n",
    "�\n",
    "=\n",
    "�\n",
    "�\n",
    "�\n",
    "+\n",
    "�\n",
    "�\n",
    "�\n",
    "SST=SSB+SSW\n",
    "\n",
    "Importance of Understanding Partitioning of Variance:\n",
    "\n",
    "Identifying Sources of Variability: By partitioning the total variance, ANOVA helps researchers identify and quantify the contributions of different sources of variability, such as group differences and random variability within groups.\n",
    "\n",
    "Assessing Significance: Understanding the partitioning of variance allows researchers to assess whether the observed differences between groups are statistically significant. This is done by comparing the between-group variability to the within-group variability.\n",
    "\n",
    "Interpreting Results: Researchers can gain insights into the proportion of total variance that is explained by the grouping variable, helping them interpret the practical significance of the observed effects.\n",
    "\n",
    "Model Diagnostics: Partitioning of variance is essential for diagnosing potential issues in the analysis, such as unequal variances between groups or violations of assumptions.\n",
    "\n",
    "Overall, a clear understanding of the partitioning of variance enhances the interpretability and validity of ANOVA results, providing researchers with valuable information about the factors influencing the dependent variable.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffe2bc3-602f-42bc-9b50-9b40a4e0c3a2",
   "metadata": {},
   "source": [
    "## Question-4 :How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c045875-6b1b-4165-8a1d-59a4a7093c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sum of Squares (SST): 1642.9333333333332\n",
      "Explained Sum of Squares (SSE): 1400.1333333333337\n",
      "Residual Sum of Squares (SSR): 242.7999999999995\n",
      "Degrees of Freedom - Between: 2\n",
      "Degrees of Freedom - Within: 12\n",
      "Mean Squares - Between: 700.0666666666668\n",
      "Mean Squares - Within: 20.23333333333329\n",
      "F-statistic: 34.599670510708485\n",
      "P-value: 1.0417714421112359e-05\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Example data (replace this with your actual data)\n",
    "group1 = np.array([10, 12, 14, 16, 18])\n",
    "group2 = np.array([25, 28, 32, 36, 40])\n",
    "group3 = np.array([5, 8, 10, 12, 15])\n",
    "\n",
    "# Combine the data into a single array\n",
    "all_data = np.concatenate([group1, group2, group3])\n",
    "\n",
    "# Calculate the overall mean\n",
    "overall_mean = np.mean(all_data)\n",
    "\n",
    "# Calculate the Total Sum of Squares (SST)\n",
    "sst = np.sum((all_data - overall_mean)**2)\n",
    "\n",
    "# Calculate the group means\n",
    "group_means = [np.mean(group) for group in [group1, group2, group3]]\n",
    "\n",
    "# Calculate the Explained Sum of Squares (SSE)\n",
    "sse = np.sum([len(group) * (mean - overall_mean)**2 for group, mean in zip([group1, group2, group3], group_means)])\n",
    "\n",
    "# Calculate the Residual Sum of Squares (SSR)\n",
    "ssr = sst - sse\n",
    "\n",
    "# Degrees of freedom\n",
    "df_between = len(group_means) - 1\n",
    "df_within = len(all_data) - len(group_means)\n",
    "\n",
    "# Mean Squares\n",
    "ms_between = sse / df_between\n",
    "ms_within = ssr / df_within\n",
    "\n",
    "# F-statistic\n",
    "f_statistic = ms_between / ms_within\n",
    "\n",
    "# p-value\n",
    "p_value = stats.f.sf(f_statistic, df_between, df_within)\n",
    "\n",
    "# Print the results\n",
    "print(\"Total Sum of Squares (SST):\", sst)\n",
    "print(\"Explained Sum of Squares (SSE):\", sse)\n",
    "print(\"Residual Sum of Squares (SSR):\", ssr)\n",
    "print(\"Degrees of Freedom - Between:\", df_between)\n",
    "print(\"Degrees of Freedom - Within:\", df_within)\n",
    "print(\"Mean Squares - Between:\", ms_between)\n",
    "print(\"Mean Squares - Within:\", ms_within)\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"P-value:\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fe9fa0-4c33-4256-83d9-8773071f53ca",
   "metadata": {},
   "source": [
    "## Question-5 :In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052d8d20-59d7-40aa-9f90-10e968bca213",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Example data (replace this with your actual data)\n",
    "data = {'A': [1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
    "        'B': ['X', 'Y', 'Z', 'X', 'Y', 'Z', 'X', 'Y', 'Z'],\n",
    "        'Value': [10, 12, 15, 14, 16, 18, 8, 10, 12]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('Value ~ C(A) + C(B) + C(A):C(B)', data=df).fit()\n",
    "\n",
    "# Print the ANOVA table\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(anova_table)\n",
    "\n",
    "# Extract main effects and interaction effects\n",
    "main_effect_A = anova_table['sum_sq']['C(A)'] / anova_table['df']['C(A)']\n",
    "main_effect_B = anova_table['sum_sq']['C(B)'] / anova_table['df']['C(B)']\n",
    "interaction_effect = anova_table['sum_sq']['C(A):C(B)'] / anova_table['df']['C(A):C(B)']\n",
    "\n",
    "# Print the main effects and interaction effect\n",
    "print(\"Main Effect A:\", main_effect_A)\n",
    "print(\"Main Effect B:\", main_effect_B)\n",
    "print(\"Interaction Effect:\", interaction_effect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4d58b8-0e77-49af-88e5-79225c2cc4c0",
   "metadata": {},
   "source": [
    "## Question-6 :Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. What can you conclude about the differences between the groups, and how would you interpret these results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedd65f6-578c-4ab3-811e-3f43b2b1e6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "In a one-way ANOVA, the F-statistic is used to test the null hypothesis that the means of several groups are equal. The p-value associated with the F-statistic helps determine whether the observed differences between the group means are statistically significant. In your case, you obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "\n",
    "Here's how to interpret these results:\n",
    "\n",
    "Null Hypothesis (H₀): The null hypothesis in ANOVA assumes that there are no significant differences between the means of the groups.\n",
    "\n",
    "Alternative Hypothesis (H₁): The alternative hypothesis states that there are significant differences between at least two group means.\n",
    "\n",
    "Interpretation of the F-statistic: The F-statistic is a ratio of the variance between groups to the variance within groups. A higher F-statistic suggests greater variability between group means relative to within-group variability. In your case, the F-statistic is 5.23.\n",
    "\n",
    "Interpretation of the p-value: The p-value associated with the F-statistic is 0.02. This p-value represents the probability of observing an F-statistic as extreme as the one calculated if the null hypothesis were true.\n",
    "\n",
    "Now, based on the p-value:\n",
    "\n",
    "If \n",
    "�\n",
    "≤\n",
    "�\n",
    "p≤α (the significance level, often set to 0.05):\n",
    "\n",
    "Conclusion: Reject the null hypothesis.\n",
    "Interpretation: There is sufficient evidence to suggest that at least two group means are significantly different.\n",
    "If \n",
    "�\n",
    ">\n",
    "�\n",
    "p>α:\n",
    "\n",
    "Conclusion: Fail to reject the null hypothesis.\n",
    "Interpretation: There is not enough evidence to claim significant differences between group means.\n",
    "In your case, with a p-value of 0.02, you would likely reject the null hypothesis at a significance level of 0.05. Therefore, you can conclude that there are significant differences between the group means. It's important to consider the context of your study and the specific research question to provide a meaningful interpretation of the results.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f9acee-f707-4a0c-9f07-0d771e0a2c37",
   "metadata": {},
   "source": [
    "## Question-7 :In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ed96a0-f482-4678-9a69-a0e457185eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Handling missing data in repeated measures ANOVA is important to ensure valid and reliable results. The way missing data is treated can impact the analysis and its outcomes. Here are common methods for handling missing data in repeated measures ANOVA and potential consequences associated with different approaches:\n",
    "\n",
    "Methods for Handling Missing Data:\n",
    "Complete Case Analysis (Listwise Deletion):\n",
    "\n",
    "Approach: Exclude cases with missing data on any variable involved in the analysis.\n",
    "Consequences:\n",
    "Reduces sample size, potentially leading to reduced statistical power.\n",
    "Assumes missing data are missing completely at random (MCAR), which may not always be a realistic assumption.\n",
    "Pairwise Deletion:\n",
    "\n",
    "Approach: Include all available data for each pair of variables when calculating means and conducting tests.\n",
    "Consequences:\n",
    "Retains more data than complete case analysis but may result in different sample sizes for different comparisons.\n",
    "Does not fully address the issue of missing data, and results may be biased if missingness is related to the dependent variable.\n",
    "Imputation:\n",
    "\n",
    "Approach: Estimate missing values and replace them with imputed values.\n",
    "Consequences:\n",
    "Preserves sample size and allows for the inclusion of cases with missing data.\n",
    "Requires making assumptions about the distribution of the missing data, and the imputed values may introduce bias.\n",
    "Last Observation Carried Forward (LOCF):\n",
    "\n",
    "Approach: Replace missing values with the last observed value for that subject.\n",
    "Consequences:\n",
    "Assumes that the last observation is a good estimate of the missing value, which may not be true.\n",
    "Can lead to biased estimates, especially if the missing data are related to changes over time.\n",
    "Potential Consequences of Different Approaches:\n",
    "Bias:\n",
    "\n",
    "The choice of handling missing data can introduce bias if the missingness is related to the dependent variable or other important variables.\n",
    "Reduced Power:\n",
    "\n",
    "Complete case analysis and LOCF can result in reduced statistical power due to a smaller effective sample size.\n",
    "Invalid Assumptions:\n",
    "\n",
    "Imputation methods assume a certain distribution for the missing data, and if these assumptions are violated, it can lead to inaccurate results.\n",
    "Impact on Generalizability:\n",
    "\n",
    "The method chosen for handling missing data can impact the generalizability of the study findings to the larger population.\n",
    "In practice, researchers should carefully consider the nature of the missing data and choose an approach that aligns with the assumptions and goals of the analysis. Sensitivity analyses, where different methods are used to handle missing data, can help assess the robustness of the findings. It is essential to transparently report the method used for handling missing data and discuss potential limitations associated with the chosen approach.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51044da-5e14-4f63-9d39-80df7a0e987e",
   "metadata": {},
   "source": [
    "## Question-8 :What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70482bc-cecd-4e23-b04e-c593621afa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Post-hoc tests are used after an Analysis of Variance (ANOVA) to further investigate pairwise differences between groups when the overall ANOVA indicates a significant difference. Here are some common post-hoc tests, along with situations where you might use each one:\n",
    "\n",
    "Tukey's Honestly Significant Difference (HSD):\n",
    "\n",
    "When to Use: Use Tukey's HSD when you have three or more groups, and you want to conduct all possible pairwise comparisons.\n",
    "Example: In a study comparing the performance of three different teaching methods, the ANOVA might indicate a significant difference. Tukey's HSD could be used to identify which specific pairs of teaching methods have significantly different means.\n",
    "Bonferroni Correction:\n",
    "\n",
    "When to Use: Use Bonferroni correction when conducting multiple pairwise comparisons to control the familywise error rate.\n",
    "Example: If you are comparing the means of multiple treatment groups, Bonferroni correction can be applied to adjust the significance level for each individual comparison, reducing the chance of Type I errors.\n",
    "Duncan's Multiple Range Test:\n",
    "\n",
    "When to Use: Use Duncan's test when you have three or more groups and want to identify homogeneous subsets with similar means.\n",
    "Example: In an agricultural study comparing the yield of different fertilizer treatments across multiple plots, Duncan's test can be applied to group treatments with similar yields.\n",
    "Scheffé's Method:\n",
    "\n",
    "When to Use: Use Scheffé's method for all possible pairwise comparisons, especially when the group sizes are unequal.\n",
    "Example: In a study comparing the effectiveness of various marketing strategies across different regions, Scheffé's method can be employed to identify regions with significantly different marketing outcomes.\n",
    "Games-Howell Test:\n",
    "\n",
    "When to Use: Use the Games-Howell test when group variances are unequal, and you need to conduct pairwise comparisons.\n",
    "Example: In a clinical trial comparing the effectiveness of several drugs on a particular health outcome, Games-Howell can be used if the variances of the drug groups are not equal.\n",
    "Example Situation Requiring Post-hoc Test:\n",
    "Let's consider an example:\n",
    "\n",
    "Scenario: A researcher conducts a one-way ANOVA to analyze the impact of three different exercise programs (A, B, C) on cardiovascular fitness levels. The ANOVA results show a significant overall difference in cardiovascular fitness among the three exercise programs.\n",
    "\n",
    "Post-hoc Test Application: To further investigate which specific exercise programs differ from each other, the researcher decides to perform Tukey's HSD post-hoc test. This test would allow the researcher to compare the means of each pair of exercise programs and identify where the significant differences lie. For instance, it may reveal that Program A and Program B have significantly different effects on cardiovascular fitness, while Program C is not significantly different from either A or B.\n",
    "\n",
    "In summary, post-hoc tests are essential in identifying specific group differences after obtaining a significant result in an ANOVA, providing more detailed insights into the nature of the observed differences among multiple groups. The choice of the post-hoc test depends on factors such as the number of groups, homogeneity of variances, and the desired control over Type I error rates.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa2cae9-012f-4934-ba6c-3bf93f384872",
   "metadata": {},
   "source": [
    "## Question-9 :A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets. Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1936f2d5-4714-4f24-b847-b16a020cc913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Sample data for each diet (replace these lists with your actual data)\n",
    "diet_A = [2.3, 1.8, 3.2, 1.5, 2.9, ...]  # 50 values\n",
    "diet_B = [1.8, 2.1, 1.5, 2.7, 2.0, ...]  # 50 values\n",
    "diet_C = [3.5, 2.8, 3.0, 2.2, 3.1, ...]  # 50 values\n",
    "\n",
    "# Combine data into a single list\n",
    "all_data = diet_A + diet_B + diet_C\n",
    "\n",
    "# Create a list of labels corresponding to the diets\n",
    "labels = ['A'] * 50 + ['B'] * 50 + ['C'] * 50\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Print results\n",
    "print(\"F-Statistic:\", f_statistic)\n",
    "print(\"P-Value:\", p_value)\n",
    "\n",
    "# Interpretation\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a significant difference between the mean weight loss of the three diets.\")\n",
    "else:\n",
    "    print(\"There is no significant difference between the mean weight loss of the three diets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe604c8e-89ea-4411-9b3b-32c464e51043",
   "metadata": {},
   "source": [
    "## Question-10 :A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs. experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a839e2c9-dbd5-4485-8085-d0c18b55bd38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
